{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dlA3h9AtJh5S",
        "outputId": "484c6b97-4e60-4aa4-9a85-aa46d902e30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package 'openjdk-11-jdk' is not installed, so not removed\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxt-dev libxtst6 libxxf86dga1\n",
            "  openjdk-17-jdk-headless openjdk-17-jre openjdk-17-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  libxt-doc openjdk-17-demo openjdk-17-source visualvm libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  | fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxt-dev libxtst6 libxxf86dga1 openjdk-17-jdk\n",
            "  openjdk-17-jdk-headless openjdk-17-jre openjdk-17-jre-headless x11-utils\n",
            "0 upgraded, 12 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 126 MB of archives.\n",
            "After this operation, 288 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre-headless amd64 17.0.15+6~us1-0ubuntu1~22.04 [48.3 MB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre amd64 17.0.15+6~us1-0ubuntu1~22.04 [232 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk-headless amd64 17.0.15+6~us1-0ubuntu1~22.04 [71.3 MB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk amd64 17.0.15+6~us1-0ubuntu1~22.04 [2,403 kB]\n",
            "Fetched 126 MB in 2s (58.5 MB/s)\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "(Reading database ... 126308 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../01-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../02-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../03-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../04-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../05-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../06-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../07-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-17-jre-headless:amd64.\n",
            "Preparing to unpack .../08-openjdk-17-jre-headless_17.0.15+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jre-headless:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-17-jre:amd64.\n",
            "Preparing to unpack .../09-openjdk-17-jre_17.0.15+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jre:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-17-jdk-headless:amd64.\n",
            "Preparing to unpack .../10-openjdk-17-jdk-headless_17.0.15+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk-headless:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-17-jdk:amd64.\n",
            "Preparing to unpack .../11-openjdk-17-jdk_17.0.15+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up openjdk-17-jre-headless:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up openjdk-17-jre:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up openjdk-17-jdk-headless:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "Setting up openjdk-17-jdk:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"17.0.15\" 2025-04-15\n",
            "OpenJDK Runtime Environment (build 17.0.15+6-Ubuntu-0ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.15+6-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n",
            "Collecting language-tool-python\n",
            "  Downloading language_tool_python-2.9.4-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting textstat\n",
            "  Downloading textstat-0.7.7-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.35.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (5.9.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting cmudict (from textstat)\n",
            "  Downloading cmudict-1.0.33-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.14)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Collecting gradio-client==1.10.4 (from gradio)\n",
            "  Downloading gradio_client-1.10.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (8.7.0)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (6.5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading language_tool_python-2.9.4-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textstat-0.7.7-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.35.0-py3-none-any.whl (54.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.4-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmudict-1.0.33-py3-none-any.whl (939 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, language-tool-python, cmudict, textstat, gradio-client, gradio\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.10.1\n",
            "    Uninstalling gradio_client-1.10.1:\n",
            "      Successfully uninstalled gradio_client-1.10.1\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.31.0\n",
            "    Uninstalling gradio-5.31.0:\n",
            "      Successfully uninstalled gradio-5.31.0\n",
            "Successfully installed cmudict-1.0.33 gradio-5.35.0 gradio-client-1.10.4 language-tool-python-2.9.4 pyphen-0.17.2 textstat-0.7.7\n",
            "--2025-07-05 10:38:14--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2025-07-05 10:40:54 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# === Setup Java 17 and Install Required Libraries ===\n",
        "!apt-get remove openjdk-11-jdk -y\n",
        "!apt-get install openjdk-17-jdk -y\n",
        "!update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-17-openjdk-amd64/bin/java 1\n",
        "!update-alternatives --set java /usr/lib/jvm/java-17-openjdk-amd64/bin/java\n",
        "!java -version\n",
        "\n",
        "# === Install Python Packages ===\n",
        "!pip install -U language-tool-python textstat nltk gradio\n",
        "!wget --no-check-certificate https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLQxSaNiJ2g-",
        "outputId": "5cd8c0e2-f9bb-4a97-8688-0c819a7ef417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBNLdZdMRWAG",
        "outputId": "633e6998-9238-484c-e67d-3f1fff036bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'random', 'text']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "sample_text = \"This is random text\"\n",
        "tokens = word_tokenize(sample_text)\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjnEluhEK_eo",
        "outputId": "84192a06-ee9b-42c4-bce3-7e54ad4fa8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import nltk\n",
        "import textstat\n",
        "import gradio as gr\n",
        "import language_tool_python\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RVcxpkW8dXRp",
        "outputId": "3ba67cf6-087f-4df4-cb80-62a4bd69d02d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 essay_id                                          full_text  \\\n",
              "0           0  000d118  Many people have car where they live. The thin...   \n",
              "1           1  000fe60  I am a scientist at NASA that is discussing th...   \n",
              "2           2  001ab80  People always wish they had the same technolog...   \n",
              "3           3  001bdc0  We all heard about Venus, the planet without a...   \n",
              "4           4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...   \n",
              "\n",
              "   score                                       cleaned_text  \n",
              "0      3  Many people have a car where they live. The th...  \n",
              "1      3  I am a scientist at NASA, discussing the \"face...  \n",
              "2      4  People always wish they had the same technolog...  \n",
              "3      4  We all heard about Venus, the planet with almo...  \n",
              "4      3  Dear State Senator,\\n\\nThis is a letter to arg...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4678af4-1e90-467d-aca2-8a91152dc269\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>score</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>000d118</td>\n",
              "      <td>Many people have car where they live. The thin...</td>\n",
              "      <td>3</td>\n",
              "      <td>Many people have a car where they live. The th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>000fe60</td>\n",
              "      <td>I am a scientist at NASA that is discussing th...</td>\n",
              "      <td>3</td>\n",
              "      <td>I am a scientist at NASA, discussing the \"face...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>001ab80</td>\n",
              "      <td>People always wish they had the same technolog...</td>\n",
              "      <td>4</td>\n",
              "      <td>People always wish they had the same technolog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>001bdc0</td>\n",
              "      <td>We all heard about Venus, the planet without a...</td>\n",
              "      <td>4</td>\n",
              "      <td>We all heard about Venus, the planet with almo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>002ba53</td>\n",
              "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
              "      <td>3</td>\n",
              "      <td>Dear State Senator,\\n\\nThis is a letter to arg...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4678af4-1e90-467d-aca2-8a91152dc269')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4678af4-1e90-467d-aca2-8a91152dc269 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4678af4-1e90-467d-aca2-8a91152dc269');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e42bd1dc-10c5-46d1-8baf-5ff940259f57\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e42bd1dc-10c5-46d1-8baf-5ff940259f57')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e42bd1dc-10c5-46d1-8baf-5ff940259f57 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 17307,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4996,\n        \"min\": 0,\n        \"max\": 17306,\n        \"num_unique_values\": 17307,\n        \"samples\": [\n          12696,\n          4625,\n          733\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17307,\n        \"samples\": [\n          \"bb4c434\",\n          \"44e88b0\",\n          \"0ba78ec\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17307,\n        \"samples\": [\n          \"People tend to use there cars so much, they basically can't live or get through the day with out their car. We use the car to go every where rather it's to the grocery store , work or just to go hang out with friends and family! Just traveling in general. Well imagine if we limited the usage of cars in our community! I strongly believe that doing this would have many advantages to our community for many reasons like it will make people less stressful all the time, there would be less accidents and it would definitly be better for the environment.\\n\\nOMG I ran out of gas or OH my i have to take my car to the shop to get it fixed is usually the two main things you hear people stay when the word \\\"car\\\" comes up. Having a car comes with alot of stress because it of expenses and having to take of its every need and usually when someone is stressed they are not the best person you wanna have a conversation with. I think that if we limit the usage of cars a lot of people in the community will be alot happier. According to the article\\n\\n\\\"Car-free Cities\\\"\\n\\nby\\n\\nElisabeth Rosenthal in source 2 a lady name Heidrun Walter says \\\" When i had a car i was always tense. I'm much happier this way.\\\" and i think that is a perfect example of limited car usauage can make a person happier.\\n\\nIn addition, I feel that if that if we limit the car usage in our community it will make this community a much safer environment. We hear and see about many car accidents in our country and community and cars can be very very dangerous. People often get injuried and/or die in car recks to. So limitting the car usage in the communitry will keep people more safe and most importantly alive . Kids will be able to run aroumd the neighborhood and play with their friends and also cross the street safely without the disruption of a car coming and stopping them from what they are doing  because they do not wants to get hurt from the car coming because they do not know who is driving the car.\\n\\nLast but not least limiting the use of car usage in the community because it would definitly be better for the environment. In science class we often talk about how cars polute the air and just mess up the waehter in the car and me my self i can also feel the car changing the more i see cars more cars in the streets. I think that it makes the days hotter and i also think that it makes the winters come around earlier and it makes it alot more colder. I live in the Sunshine florida and in the south. So all year round its usually hot extremly hot but has i realize more people are driving around the winers seem ALOT more cold then it usually is and the cold last for longer periods of time.\\n\\nIn conclusion, I belive that if we limit the car usuage in our community it will make it a better place for many reasons. Like it will make people less stressful and  be happier, there will be less accidents on the road and it will also help the environment a lot.                        \",\n          \"Imagine being a top scientist at NASA and Viking 1 spacecraft \\\"spotted the shadowy likeness of a human face.\\\" A lot of people thought of alien life possibility, but others thought it to be just a natural landform. What would your thoughts be about the image? The face of Mars is a natural landform. There's similar landforms on Earth, high pixel photos taken, and not enough reliable information to support the alien life theory.\\n\\nTo begin, there are similar landforms on Earth to the one on Mars. As stated in the text, \\\"what the picture actually shows is the Martian equivalent of a butte or mesa- landforms common around the American West.\\\" Also stated in the text is Garvin giving his opinion, \\\"it reminds me most of Middle Butte in the Snake River Plain of Idaho.\\\"\\n\\nAnother issue with the alien life theory is the fact that NASA has high quality cameras. Quoting the text, \\\"each pixel in the 2001 image spans 1.56 meters, compared to 43 meters per pixel in the best 1976 Viking photo.\\\" In the result of having high quality pictures you could see small details clearly. As stated in the article Garvin said, \\\" 'so, if there were objects in this picture like airplanes on the ground or Egyptian-style pyramids or even small shacks, you could see what they were!' \\\" Concluding that statement nothing other than the landform that had resembled a face was seen on Mars.\\n\\nFinally, there wasn't enough evidence to support the claim of alien life on Mars. The first pictures were blurry and had haze or cloud coverage. This theory was more popular on the online world than in the science world. As stated in the text, \\\"the 'Face on Mars' has since become a pop icon. It has starred in a Hollywood film, appeared in books, magazines, radio talk shows-even haunted grocery store checkout lines for 25 years!\\\" This proves that this might be just for publicity and attention. There has been many conspiracy theorists.\\n\\nUltimately, the face on Mars is just a natural landform. There's similar landforms on Earth, high pixel photos taken, and not enough reliable information to support the alien life theory.       \",\n          \"The face of Mars could not be created by aliens. It is a land form created by the conditions of mars and looks like a face only by coincidence. Mesa's are common in this area of Mars and there are many others like this one just without the same shadows which makes the appearance of a human's face.\\n\\nOut of so many different land forms in Cydonia why should this be any different. In the second paragrapgh of the article, it stated that the Cydonia region is known for its buttes and mesas. The face of Mars is just another mesa no different that any other one except for its unique shadows. It is strange to see a formation on an supposedly uninhabited planet that depicts a \\\"human\\\" face. Espescially when no human has ever set foot on the planet of Mars before. But at the same time, that is all the more reason to believe that this is nothing more that a weird coincidence since no person has ever been there.\\n\\nTo conspiracy theorists dismay, this strange landform is nothing more than martian butte or mesa and a weird coincidence. It is an interesting formation that stumped and puzzled scientests all over the world. But we now know the formation is not anything that will reveal alien lifeforms or alien activity.        \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3,\n          4,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17307,\n        \"samples\": [\n          \"People tend to use their cars so much that they basically can't live or get through the day without their car. We use the car to go everywhere, whether it's to the grocery store, work, or just to hang out with friends and family! Just traveling in general. Well, imagine if we limited the usage of cars in our community! I strongly believe that doing this would have many advantages to our community for many reasons, like it will make people less stressed all the time, there would be less accidents, and it would definitely be better for the environment.\\n\\nOh my, I ran out of gas or I have to take my car to the shop to get it fixed is usually the two main things you hear people say when the word \\\"car\\\" comes up. Having a car comes with a lot of stress because of expenses and having to take care of its every need, and usually when someone is stressed, they are not the best person you want to have a conversation with. I think that if we limit the usage of cars, a lot of people in the community will be a lot happier. According to the article \\\"Car-free Cities\\\" by Elisabeth Rosenthal, a lady named Heidrun Walter says, \\\"When I had a car, I was always tense. I'm much happier this way.\\\" And I think that is a perfect example of how limited car usage can make a person happier.\\n\\nIn addition, I feel that if we limit the car usage in our community, it will make this community a much safer environment. We hear and see about many car accidents in our country and community, and cars can be very dangerous. People often get injured and/or die in car wrecks. So, limiting the car usage in the community will keep people more safe and most importantly, alive. Kids will be able to run around the neighborhood and play with their friends and also cross the street safely without the disruption of a car coming and stopping them from what they are doing, because they do not want to get hurt from the car coming because they do not know who is driving the car.\\n\\nLast but not least, limiting the use of car usage in the community because it would definitely be better for the environment. In science class, we often talk about how cars pollute the air and just mess up the weather. I think that it makes the days hotter and I also think that it makes the winters come around earlier and it makes it a lot colder. I live in the Sunshine, Florida, and in the south. So, all year round, it's usually hot, extremely hot, but as I realize more people are driving around, the winters seem a lot more cold than it usually is, and the cold lasts for longer periods of time.\\n\\nIn conclusion, I believe that if we limit the car usage in our community, it will make it a better place for many reasons. Like it will make people less stressed and be happier, there will be less accidents on the road, and it will also help the environment a lot.\",\n          \"Imagine being a top scientist at NASA and Viking 1 spacecraft \\\"spotted the shadowy likeness of a human face.\\\" A lot of people thought of alien life possibility, but others thought it to be just a natural landform. What would your thoughts be about the image? The face of Mars is a natural landform. There's similar landforms on Earth, high pixel photos taken, and not enough reliable information to support the alien life theory.\\n\\nTo begin, there are similar landforms on Earth to the one on Mars. As stated in the text, \\\"what the picture actually shows is the Martian equivalent of a butte or mesa - landforms common around the American West.\\\" Also stated in the text is Garvin giving his opinion, \\\"it reminds me most of Middle Butte in the Snake River Plain of Idaho.\\\"\\n\\nAnother issue with the alien life theory is the fact that NASA has high-quality cameras. Quoting the text, \\\"each pixel in the 2001 image spans 1.56 metres, compared to 43 metres per pixel in the best 1976 Viking photo.\\\" In the result of having high-quality pictures, you could see small details clearly. As stated in the article, Garvin said, \\\" 'so, if there were objects in this picture like airplanes on the ground or Egyptian-style pyramids or even small shacks, you could see what they were!' \\\" Concluding that statement, nothing other than the landform that had resembled a face was seen on Mars.\\n\\nFinally, there wasn't enough evidence to support the claim of alien life on Mars. The first pictures were blurry and had haze or cloud coverage. This theory was more popular on the online world than in the science world. As stated in the text, \\\"the 'Face on Mars' has since become a pop icon. It has starred in a Hollywood film, appeared in books, magazines, radio talk shows - even haunted grocery store checkout lines for 25 years!\\\" This proves that this might be just for publicity and attention. There has been many conspiracy theorists.\\n\\nUltimately, the face on Mars is just a natural landform. There's similar landforms on Earth, high-pixel photos taken, and not enough reliable information to support the alien life theory.\",\n          \"The face of Mars could not be created by aliens. It is a landform created by the conditions of Mars and looks like a face only by coincidence. Mesas are common in this area of Mars and there are many others like this one, just without the same shadows which make the appearance of a human's face.\\n\\nOut of so many different landforms in Cydonia, why should this be any different? In the second paragraph of the article, it stated that the Cydonia region is known for its buttes and mesas. The face of Mars is just another mesa, no different from any other one, except for its unique shadows. It is strange to see a formation on an supposedly uninhabited planet that depicts a \\\"human\\\" face. Especially when no human has ever set foot on the planet of Mars before. But at the same time, that is all the more reason to believe that this is nothing more than a weird coincidence, since no person has ever been there.\\n\\nTo conspiracy theorists' dismay, this strange landform is nothing more than a Martian butte or mesa and a weird coincidence. It is an interesting formation that stumped and puzzled scientists all over the world. But we now know the formation is not anything that will reveal alien lifeforms or alien activity.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Data/essay_llama3_8B_groq.csv\").dropna()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoxGfBbcL2Bz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Data/essay_llama3_8B_groq.csv\").dropna()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    return text\n",
        "\n",
        "df['cleaned_essay'] = df['cleaned_text'].apply(clean_text)\n",
        "\n",
        "X = df['cleaned_essay']\n",
        "y = df['score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5cuDf8OMKSu"
      },
      "outputs": [],
      "source": [
        "max_words = 10000\n",
        "max_len = 300\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_len)\n",
        "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQfqGpjOMNNe"
      },
      "outputs": [],
      "source": [
        "embedding_index = {}\n",
        "with open(\"glove.6B.100d.txt\", encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = coefs\n",
        "\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "word_index = tokenizer.word_index\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR1YJ5N3MVFV",
        "outputId": "651d5e2f-2a45-49a4-97af-08f471c91b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 456ms/step - loss: 1.5409 - val_loss: 0.9440\n",
            "Epoch 2/5\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 456ms/step - loss: 1.0655 - val_loss: 0.6047\n",
            "Epoch 3/5\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 489ms/step - loss: 0.7092 - val_loss: 0.5828\n",
            "Epoch 4/5\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 469ms/step - loss: 0.6805 - val_loss: 0.5735\n",
            "Epoch 5/5\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 469ms/step - loss: 0.6680 - val_loss: 0.5404\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len,\n",
        "              weights=[embedding_matrix], trainable=False),\n",
        "    LSTM(128),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_seq, y_train, epochs=5, batch_size=32,\n",
        "                    validation_split=0.1, callbacks=[early_stop])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0iY5UHrO6XK",
        "outputId": "02cce21f-2666-4f82-8ff8-00a306d32a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 363ms/step\n",
            "MSE: 0.5900195837020874\n",
            "QWK: 0.5964576548226079\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test_seq)\n",
        "y_pred_rounded = np.clip(np.rint(y_pred), 0, 6)\n",
        "\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"QWK:\", cohen_kappa_score(y_test.astype(int), y_pred_rounded.astype(int), weights='quadratic'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAghK19MO-5K"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/aes_lstm_glove_model.keras\")\n",
        "with open(\"/content/drive/MyDrive/aes_tokenizer_glove.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_60AcbymPE4C"
      },
      "outputs": [],
      "source": [
        "def extract_keywords(text, top_n=20):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    X = vectorizer.fit_transform([text])\n",
        "    scores = X.toarray()[0]\n",
        "    indices = np.argsort(scores)[::-1][:top_n]\n",
        "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "    return feature_names[indices]\n",
        "\n",
        "def content_score(essay_text, keywords):\n",
        "    essay_lower = essay_text.lower()\n",
        "    matched_keywords = [word for word in keywords if word in essay_lower]\n",
        "    score = len(matched_keywords) / len(keywords) * 4  # Max 4 points for content\n",
        "    return round(score, 2), matched_keywords\n",
        "\n",
        "def generate_feedback(pred_score, essay_text, content_keywords):\n",
        "    import language_tool_python\n",
        "    tool = language_tool_python.LanguageTool('en-US')\n",
        "\n",
        "    if pred_score >= 5:\n",
        "        summary = \"Excellent structure and clear arguments. Well done!\"\n",
        "    elif pred_score >= 4:\n",
        "        summary = \"Good essay overall. You can improve argument depth and cohesion.\"\n",
        "    elif pred_score >= 3:\n",
        "        summary = \"Fair effort. Focus on clearer structure and stronger evidence.\"\n",
        "    elif pred_score >= 2:\n",
        "        summary = \"Needs improvement. Clarify your position and organize ideas better.\"\n",
        "    else:\n",
        "        summary = \"Work on developing your thesis and supporting it with clear reasons.\"\n",
        "\n",
        "    feedback_points = []\n",
        "    words = word_tokenize(essay_text)\n",
        "    sentences = sent_tokenize(essay_text)\n",
        "\n",
        "    if len(words) < 150:\n",
        "        feedback_points.append(\"Essay is too short — expand your arguments.\")\n",
        "    if len(sentences) < 5:\n",
        "        feedback_points.append(\"Use more sentence variety and elaboration.\")\n",
        "    if textstat.flesch_reading_ease(essay_text) < 40:\n",
        "        feedback_points.append(\"Simplify sentence structure for better clarity.\")\n",
        "    if \"however\" not in essay_text.lower() and \"on the other hand\" not in essay_text.lower():\n",
        "        feedback_points.append(\"Use transition words to improve logical flow.\")\n",
        "\n",
        "    matches = tool.check(essay_text)\n",
        "    if len(matches) > 0:\n",
        "        feedback_points.append(f\"Grammar issues detected: {len(matches)} potential problems.\")\n",
        "\n",
        "    content_marks, matched_keywords = content_score(essay_text, content_keywords)\n",
        "    feedback_points.append(f\"Content Score: {content_marks}/4. Keywords matched: {', '.join(matched_keywords)}\")\n",
        "\n",
        "    suggestions = \" \".join(feedback_points)\n",
        "    return f\"{summary}\\n\\nSuggestions:\\n{suggestions if suggestions else 'None. Keep it up!'}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "yDDFw_JHPOS_",
        "outputId": "4c21365b-6409-4663-b917-992cc541a1e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cbd452f81a47fe703f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cbd452f81a47fe703f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "def score_essay(essay):\n",
        "    try:\n",
        "        extracted_keywords = extract_keywords(essay)\n",
        "        cleaned = clean_text(essay)\n",
        "        seq = tokenizer.texts_to_sequences([cleaned])\n",
        "        padded = pad_sequences(seq, maxlen=max_len)\n",
        "        pred = model.predict(padded)\n",
        "        score = int(np.clip(np.rint(pred), 0, 6).item())\n",
        "        feedback = generate_feedback(score, essay, extracted_keywords)\n",
        "        return score, feedback\n",
        "    except Exception as e:\n",
        "        return \"Error\", f\"Exception occurred: {str(e)}\"\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=score_essay,\n",
        "    inputs=gr.Textbox(lines=20, label=\"Enter Essay\"),\n",
        "    outputs=[\n",
        "        gr.Number(label=\"Predicted Score (0–6)\"),\n",
        "        gr.Textbox(label=\"Feedback\")\n",
        "    ],\n",
        "    title=\"Automated Essay Scoring (AES) with LSTM + GloVe\",\n",
        "    description=\"Enter an argumentative essay to receive an automated score and feedback, including content-based evaluation.\",\n",
        "    examples=[\n",
        "        [\"Technology has significantly improved our lives in many ways. From faster communication...\"],\n",
        "        [\"Wales had been integrated into the Kingdom of England by the Laws in Wales Acts 1535...\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "interface.launch(share=True)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}